{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Make sure that you have all these libaries available to run the code successfully\n",
    "#from pandas_datareader import data\n",
    "#print(\"Importing...\")\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import urllib.request, json\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf # This code has been tested with TensorFlow 1.6\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout \n",
    "import time\n",
    "import pickle\n",
    "import requests\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open('bin/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('bin/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def createDataframe(inFile, skip, dateField,priceField,separator):\n",
    "    targetFile = open('datafile.csv','w') \n",
    "    file = open(inFile, 'r') \n",
    "    i=0\n",
    "    for line in file: \n",
    "        i+=1\n",
    "        if i>skip:\n",
    "            targetFile.write(line)\n",
    "    targetFile.close() \n",
    "    # Read in price field as string, and convert it later\n",
    "    df = pd.read_csv('datafile.csv', sep=separator, converters={priceField: str})\n",
    "    df = df.sort_values('Date', ascending=True).dropna()\n",
    "    \n",
    "    prices = df[[dateField,priceField]]\n",
    "    # Replacing commas before typecasting \n",
    "    df[priceField].replace(',','.',inplace=True)\n",
    "    # Typecasting\n",
    "    df[priceField] = df[priceField].astype(float)\n",
    "    # Renaming collumns\n",
    "    df.rename(columns={dateField: 'Date', priceField:'Close'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "#df = createDataframe('NOVO-B.CO.csv', 0,'Date','Close',',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createWindowedDataset(df, window_size, column='Close'):\n",
    "    #from pandas import ordered_merge\n",
    "    # Scale the data to be between 0 and 1\n",
    "    # When scaling remember! You normalize both test and train data with respect to training data\n",
    "    # Because you are not supposed to have access to test data\n",
    "    print('Shape '+str(df.shape))\n",
    "    # scale values\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaled=scaler.fit_transform(df[[column]])\n",
    "    series=pd.DataFrame(scaled)\n",
    "    \n",
    "    # Creating windowed dataset\n",
    "    #print('Shape '+str(series.shape))\n",
    "    series_s = series.copy()\n",
    "    for i in range(window_size):\n",
    "        prev = series_s.shift(-(i+1))\n",
    "        prev.name = str(i)\n",
    "        series = pd.concat([series, prev],axis=1)\n",
    "    series.dropna(axis=0, inplace=True)\n",
    "    newDF = series\n",
    "    newDF.dropna(axis=0, inplace=True)\n",
    "    return newDF, scaler\n",
    "#createWindowedDataset(df,25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainNumberOfRows(fraction, series):\n",
    "    nrow = round(fraction*series.shape[0])\n",
    "    return nrow\n",
    "#nrow = getTestNumberOfRows(0.8,ds)\n",
    "#nrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel(window_size):\n",
    "    model = Sequential()\n",
    "    #model.add(LSTM(input_shape=(window_size,1), output_dim=window_size, return_sequences = True))\n",
    "    model.add(LSTM(return_sequences=True, input_shape=(window_size, 1), units=50))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.compile(loss=\"mse\",optimizer=\"adam\")\n",
    "    model.summary\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(nrow, model, train_data_predictors, train_data_target, test_data_predictors, test_data_target):   \n",
    "    start = time.time()\n",
    "    model.fit(train_data_predictors,train_data_target,batch_size=512,epochs=20,validation_split=0.1, verbose=0)\n",
    "    print(\"> Compilation Time : \", time.time() - start)\n",
    "    return model\n",
    "#trainedModel = trainModel(nrow, model, ds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def downloadSymbolHistory(symbol, maxDate='2999-12-31', mode='persisted'):\n",
    "    # Downloads historik data for symbol.\n",
    "    # Filters rows newer than maxDate, so that historic data can be simmulated\n",
    "    # and training the model as of any given historic date can be performed\n",
    "    \n",
    "    if mode.upper()!='DOWNLOAD':\n",
    "        myDf=load_obj(symbol)\n",
    "        print(\"Note: Loaded persisted time series data\")\n",
    "        return myDf[myDf.index<=maxDate]#.tail(1000)\n",
    "    url = \"https://www.alphavantage.co/query\"\n",
    "    function = \"TIME_SERIES_DAILY\"\n",
    "    #symbol = \"MSFT\"\n",
    "    api_key = \"JS1OH18PC49XLGCG\"   \n",
    "    datatype = \"json\"\n",
    "    outputsize = \"full\"\n",
    "\n",
    "    data = { \"function\"   : function, \n",
    "             \"symbol\"     : symbol, \n",
    "             \"apikey\"     : api_key ,\n",
    "             \"datatype\"   : datatype,\n",
    "             \"outputsize\" : 'full'} \n",
    "    print(\"For \"+symbol)\n",
    "    print(\"Note: Downloading time series data from \"+url)\n",
    "    page = requests.get(url, params = data)\n",
    "    response_data = page.json()\n",
    "    #print(response_data)\n",
    "    try:\n",
    "        timeSeriesJson = (response_data[\"Time Series (Daily)\"])\n",
    "    except:\n",
    "        print(\"Error - retrying every 30 secs...\")\n",
    "        for i in range(1,5):\n",
    "            try:\n",
    "                time.sleep(30)\n",
    "                print(\"Retrying...\")\n",
    "                page = requests.get(url, params = data)\n",
    "                response_data = page.json()\n",
    "                timeSeriesJson = (response_data[\"Time Series (Daily)\"])\n",
    "                print(\"Success\")\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "            if i == 5:\n",
    "                print(\"Did not succeed after 5 retrys, exiting\")\n",
    "                exit(6)\n",
    "        #print(timeSeriesJson)\n",
    "    #print(\"Number of datarows downloaded: \"+str(len(timeSeriesJson)))\n",
    "    myDict = {}\n",
    "    for key, value in timeSeriesJson.items():\n",
    "        myDict[key] = value.get('4. close')\n",
    "    myDf = pd.DataFrame.from_dict(myDict, orient='index')    \n",
    "    myDf.columns = ['Close']\n",
    "    myDf.index.name = 'Date'\n",
    "    myDf.sort_index(inplace=True, ascending=True)\n",
    "    \n",
    "    lst = []\n",
    "    prevLst = []\n",
    "    #prevClose=myDf.iloc[0,0].Close\n",
    "    prevClose = 1\n",
    "    for index, row in myDf.iterrows():\n",
    "        if row['Close'] == 0:\n",
    "            Close = prevClose\n",
    "        else:\n",
    "            Close = row['Close']\n",
    "        if float(row['Close']) != 0:\n",
    "            prevClose = Close\n",
    "        lst.append(Close)\n",
    "        prevLst.append(prevClose)\n",
    "    #se = pd.Series(lst)\n",
    "    myDf['Close'] = pd.Series(prevLst).values\n",
    "    #myDf['Prev']  = pd.Series(prevLst).values\n",
    "    \n",
    "    #print(se)\n",
    "    \n",
    "    #print(myDf)    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    counter=0\n",
    "    rel = []\n",
    "    for index, row in myDf.iterrows():\n",
    "        if counter==0:\n",
    "            prev=float(row['Close'])\n",
    "            #print(float(row['Close']))\n",
    "        r=(float(row['Close'])-prev)/float(row['Close'])\n",
    "        rel.append(r)\n",
    "        counter+=1\n",
    "        prev=float(row['Close'])\n",
    "    #print(len(rel))\n",
    "    se = pd.Series(rel)\n",
    "    #print(se)\n",
    "    myDf['Relative'] = se.values\n",
    "    save_obj(myDf,symbol)\n",
    "    return myDf[myDf.index<=maxDate]#.tail(1000)\n",
    "\n",
    "#downloadSymbolHistory('DANSKE.CPH', '2099-12-31', 'download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareAndTrain(symbol,df, maxDate='2999-12-31', window_size=50, column='Close',plot=True):\n",
    "    alphaVantageAipKey='JS1OH18PC49XLGCG'\n",
    "    #window_size=50\n",
    "    #trainNRows = getTrainNumberOfRows(0.8,ds)\n",
    "    #symbols = ['GOOGL']\n",
    "    \n",
    "    \n",
    "    # Create the windowd dataframe\n",
    "    series, scaler = createWindowedDataset(df,window_size, column)\n",
    "    trainNrows = getTrainNumberOfRows(0.97,series)\n",
    "    # Define the model\n",
    "    model=buildModel(window_size)    \n",
    "    # Create the train and test-dataset\n",
    "    # Use the first\n",
    "    print('trainNrows: '+str(trainNrows))\n",
    "    #print('DS shape '+str(df.shape))\n",
    "    train = series.iloc[:trainNrows, :]\n",
    "    test = series.iloc[trainNrows:,:]\n",
    "    # Now, shuffle the train-set\n",
    "    from sklearn.utils import shuffle\n",
    "    train = shuffle(train)\n",
    "    # train_X is all rows, all columns minus last, which is the target variable\n",
    "    train_X = train.iloc[:,:-1].values\n",
    "    # train_y is all rows, last column only, which is the target variable\n",
    "    train_y = train.iloc[:,-1].values\n",
    "    test_X = test.iloc[:,:-1].values\n",
    "    test_y = test.iloc[:,-1].values\n",
    "    print('**')\n",
    "    train_X = train_X.reshape(train_X.shape[0],train_X.shape[1],1)\n",
    "    test_X = test_X.reshape(test_X.shape[0],test_X.shape[1],1)\n",
    "    trainedModel = trainModel(trainNrows, model, train_X, train_y, test_X, test_y)\n",
    "        \n",
    "    from matplotlib import pyplot\n",
    "    ac=np.asarray(test_y).reshape(-1,1)\n",
    "    actuals = scaler.inverse_transform(ac)\n",
    "    pd = trainedModel.predict(test_X)\n",
    "    predicts=scaler.inverse_transform(pd)\n",
    "    mape = mean_absolute_percentage_error(actuals,predicts)\n",
    "    if plot==True:\n",
    "        pyplot.plot(actuals)\n",
    "        pyplot.plot(predicts)\n",
    "        pyplot.show()\n",
    "        import pandas as pd\n",
    "        d = pd.DataFrame({'actuals':actuals.flatten('F'), 'predicts':predicts.flatten('F')})\n",
    "        print(\"Mean Absolute Error: \"+str(mean_absolute_error(actuals,predicts)))\n",
    "        print(\"Mean Squared Error: \"+str(mean_squared_error(actuals,predicts)))\n",
    "        print(\"Mean Absolute Percentage Error: \"+str(mape))\n",
    "    #return df, trainedModel, scaler, mape\n",
    "    return trainedModel, scaler, mape\n",
    "\n",
    "#data, tm, sc = prepareAndTrain('GOOGL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to predict n future values.\n",
    "# Returns list of n predictions as numpy array, and last prediction as float\n",
    "#input = test_X[0]\n",
    "nDays = 5\n",
    "def predictNdays(nDays, trainedModel, scaler, inputSequence):\n",
    "    preds_moving = []                                    # Use this to store the prediction made on each test window\n",
    "    moving_test_window = [inputSequence]          # Creating the first test window\n",
    "    moving_test_window = np.array(moving_test_window)    # Making it an numpy array\n",
    "    \n",
    "    for i in range(nDays):\n",
    "        #print(i)\n",
    "        preds_one_step = trainedModel.predict(moving_test_window) # Note that this is already a scaled prediction so no need to rescale this\n",
    "        preds_moving.append(preds_one_step[0,0]) # get the value from the numpy 2D array and append to predictions\n",
    "        preds_one_step = preds_one_step.reshape(1,1,1) # Reshaping the prediction to 3D array for concatenation with moving test window\n",
    "        moving_test_window = np.concatenate((moving_test_window[:,1:,:], preds_one_step), axis=1) # This is the new moving test window, where the first element from the window has been removed and the prediction  has been appended to the end\n",
    "    lastNDaysPredictions = moving_test_window[0][len(moving_test_window)-(nDays+2):]\n",
    "    nthDayPrediction = lastNDaysPredictions[0].tolist()[0]\n",
    "    lastDayPrediction = scaler.inverse_transform(nthDayPrediction)[0][0]\n",
    "    return scaler.inverse_transform(lastNDaysPredictions), lastDayPrediction\n",
    "\n",
    "#predictNdays(5, trainedModel, scaler, test_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the code that will run continously.\n",
    "We´ll skip the test-part, because we´re now only predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(symbol, window_size, predictDays, data, tm, sc, maxDate='2999-12-31', column='Close'):\n",
    "    #data, tm, sc, mape = prepareAndTrain(symbol, maxDate, window_size,column, True)\n",
    "    se,sc = createWindowedDataset(data,window_size, column)\n",
    "    latestSequence=se[len(se)-1:].values\n",
    "    latestSequence = latestSequence.reshape(latestSequence.shape[1],latestSequence.shape[0])[len(latestSequence):]\n",
    "    nDays, nThDay = predictNdays(predictDays, tm, sc, latestSequence)\n",
    "    sc.inverse_transform(latestSequence)\n",
    "    nDays, nThDay\n",
    "    return nDays, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the closing price for the following trading day\n",
    "def getNextClose(symbol, date='2999-12-31', column='Close'):\n",
    "    if date=='2999-12-31':\n",
    "        print(\"Error: No date supplied - cannot get next closingprice\")\n",
    "    data = downloadSymbolHistory(symbol)\n",
    "    data.insert(0, 'row_num', range(0,len(data)))  # here we insert the row count\n",
    "    y = data.loc[date]['row_num']\n",
    "    nextClose=data.loc[data['row_num'] == y+1]\n",
    "    return pd.to_numeric(nextClose[column], errors='coerce').tolist()[0]\n",
    "#getNextClose('NYSE:AXP', date='2017-12-12')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list of valid tradingdays for the supplied symbol\n",
    "def getTradingDays(symbol):\n",
    "    data = downloadSymbolHistory(symbol)\n",
    "    return data.index.tolist()\n",
    "#getTradingDays('NYSE:AXP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getTradingDays('DWDP')\n",
    "#getNextClose('DWDP', '2018-07-02')\n",
    "#downloadSymbolHistory('DWDP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nDays, nThDay = predictNdays(nDays, tm, sc)\n",
    "import time\n",
    "#############################\n",
    "# Setup                     #\n",
    "#############################\n",
    "sleepSecs = 600\n",
    "results = {}\n",
    "funds=10000\n",
    "trainOnce=True\n",
    "symbols = ['MMM','AXP','AAPL','BA','CAT','CVX','CSCO','KO','DIS','DWDP','XOM','GS','HD','IBM','INTC','JNJ','JPM','MCD','MRK','MSFT','NKE','PFE','PG','TRV','UTX','UNH','VZ','V','WMT','WBA']\n",
    "#symbols = ['JNJ','JPM','MCD','MRK','MSFT','NKE','PFE','PG','TRV','UTX','UNH','VZ','V','WMT','WBA']\n",
    "#symbols = ['BA']\n",
    "column='Close'\n",
    "window_size=50\n",
    "symbolGains = {}\n",
    "\n",
    "#############################\n",
    "for symbol in symbols:\n",
    "    break\n",
    "    downloadSymbolHistory(symbol,'2999-12-31','download')\n",
    "    days = [days for days in getTradingDays(symbol) if days >= '2018-07-01' and days < '2018-08-01']\n",
    "    print(\"*****************************\")\n",
    "    print(\"Simmulating \"+str(len(days))+\" days for \"+symbol)\n",
    "    #tradingDays=getTradingDays(symbol)\n",
    "    dayNumber=0\n",
    "    for day in days:\n",
    "        startFunds=funds\n",
    "        dayNumber+=1\n",
    "        print(\"\")\n",
    "        print (time.strftime(\"%H:%M:%S\"))\n",
    "        print(\"***\")\n",
    "        print(\"Simmulating \"+symbol+\" at date: \"+day)\n",
    "        #break\n",
    "        data=downloadSymbolHistory(symbol, day)\n",
    "        if dayNumber==1:\n",
    "            print(\"Training...\")\n",
    "            tm, sc, mape = prepareAndTrain(symbol, data, day, window_size,column, True)\n",
    "        else:\n",
    "            if trainOnce==False:\n",
    "                print(\"Training...\")\n",
    "                tm, sc, mape = prepareAndTrain(symbol,data, day, window_size,column, True)\n",
    "        nDays, mape = predict(symbol,window_size,5, data, tm, sc, day, column) #Close vs Relative\n",
    "        latestClose=nDays[0][0]\n",
    "        nextClose=nDays[1][0]\n",
    "        fourDaysClose=nDays[4][0]\n",
    "        actualNextClose=getNextClose(symbol, day, column)\n",
    "        gainPct = round((nextClose-latestClose)/latestClose*100,2)    \n",
    "        fourDaysGainPct = round((fourDaysClose-latestClose)/latestClose*100,2)        \n",
    "        print(\"***\")\n",
    "        print(symbol+\":\")\n",
    "        print(\"MAPE             :\"+str(mape))        \n",
    "        if column == 'Close':\n",
    "            print(\"Latest close     : \"+str(latestClose))\n",
    "            print(\"Next close       : \"+str(nextClose)+\" (\"+str(gainPct)+\"%)\")\n",
    "            print(\"4 Days close     : \"+str(fourDaysClose)+\" (\"+str(fourDaysGainPct)+\"%)\")\n",
    "            print(\"Actual next close: \"+str(actualNextClose))\n",
    "            if gainPct>0.50:\n",
    "                print(\"Bying and selling - funds before: \"+str(round(funds,2)))\n",
    "                funds=(funds/latestClose*actualNextClose)-29\n",
    "                print(\"Bought and sold - funds now: \"+str(round(funds,4)))\n",
    "        if column == 'Relative':\n",
    "            print(\"Latest close     : \"+str(round(latestClose*100,4))+'%')\n",
    "            print(\"Next close       : \"+str(round(nextClose*100,4))+\"%\")\n",
    "            print(\"4 Days close     : \"+str(round(fourDaysClose*100,4))+\"%\")\n",
    "            print(\"Actual next close: \"+str(round(actualNextClose*100,4))+\"%\")\n",
    "            if nextClose>0.005:\n",
    "                print(\"Bying and selling - funds before: \"+str(round(funds,2)))\n",
    "                funds=(funds*(actualNextClose+1))-29\n",
    "                print(\"Bought and sold - funds now: \"+str(round(funds,2)))\n",
    "        results[symbol]=[nDays,[mape]]\n",
    "    print(\"Funds total: \"+str(round(funds,2)))\n",
    "    symbolGains[symbol]=str(round((funds-startFunds)/funds*100,4))+'%'\n",
    "    print(symbolGains)\n",
    "    \n",
    "    #print(\"Sleeping before next symbol\")\n",
    "    #time.sleep(sleepSecs)\n",
    "    \n",
    "    \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for key, value in results.items():\n",
    "#    nDays=value[0]\n",
    "#    mape = value[1]\n",
    "#    #print(mape[0])\n",
    "#    print(key+\":\")\n",
    "#    print(\"Mean Percentage Absolute Error: \"+str(round(mape[0],2))+\"%\")\n",
    "#    print(\"Latest close                  : \"+str(nDays[0][0]))\n",
    "#    print(\"Next close                    : \"+str(nDays[1][0])+\" (\"+str(round((nDays[1][0]-nDays[0][0])/nDays[0][0]*100,2))+\"%)\")\n",
    "#    print(\"Close in \"+str(len(nDays)-1)+\" days               : \"+str(nDays[5][0])+\" (\"+str(round((nDays[5][0]-nDays[0][0])/nDays[0][0]*100,2))+\"%)\")\n",
    "#    print('***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing classic SMA (Simple Moving Average) (shot/long) and looking for \"golden cross\" and \"death cross\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from os.path import basename\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.utils import COMMASPACE, formatdate\n",
    "\n",
    "\n",
    "def sendMail(send_from, send_to, subject, text, files, server=\"smtp.gmail.com:587\"):\n",
    "    #assert isinstance(send_to, list)\n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = send_from\n",
    "    #msg['To'] = COMMASPACE.join(send_to)\n",
    "    msg['To'] = send_to\n",
    "    msg['Date'] = formatdate(localtime=True)\n",
    "    msg['Subject'] = subject\n",
    "\n",
    "    msg.attach(MIMEText(text))\n",
    "\n",
    "    for f in files or []:\n",
    "        with open(f, \"rb\") as fil:\n",
    "            part = MIMEApplication(\n",
    "                fil.read(),\n",
    "                Name=basename(f)\n",
    "            )\n",
    "        # After the file is closed\n",
    "        part['Content-Disposition'] = 'attachment; filename=\"%s\"' % basename(f)\n",
    "        msg.attach(part)\n",
    "\n",
    "\n",
    "    smtp = smtplib.SMTP(server)\n",
    "    smtp.starttls()\n",
    "    smtp.login(send_from, 'imbphmnawhmakajq')\n",
    "    smtp.sendmail(send_from, send_to, msg.as_string())\n",
    "    smtp.close()\n",
    "#sendMail('pedersbak@gmail.com','pedersbak@gmail.com', 'My subject', 'My message', ['output.pdf'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-8e4e40f42a73>, line 161)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-8e4e40f42a73>\"\u001b[0;36m, line \u001b[0;32m161\u001b[0m\n\u001b[0;31m    signals[symbol]=SMA Buy'\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from fpdf import FPDF\n",
    "import math\n",
    "import datetime\n",
    "plot=True\n",
    "verbose=False\n",
    "funds=10000\n",
    "portfolio={}\n",
    "\n",
    "def buy(symbol, price, message=None):\n",
    "    global funds\n",
    "    global portfolio\n",
    "    global verbose\n",
    "    numberOfShares = math.floor(funds/price)\n",
    "    rest = funds-numberOfShares*price\n",
    "    funds=rest\n",
    "    if portfolio.get(symbol,'NA')=='NA':\n",
    "        if verbose==True:\n",
    "            print(\"************\")\n",
    "            if message!=None:\n",
    "                print(message)\n",
    "            print(\"Buying \"+str(numberOfShares)+\" \"+symbol+\" at \"+str(price)+\" totalling \"+str(numberOfShares*price))\n",
    "            print(\"Funds now: \"+str(funds))\n",
    "        portfolio[symbol]=numberOfShares\n",
    "\n",
    "def sell(symbol, price, message=None):\n",
    "    global funds\n",
    "    global portfolio\n",
    "    global verbose\n",
    "    if portfolio.get(symbol,'NA')!='NA':\n",
    "        funds=funds+portfolio.get(symbol)*price\n",
    "        numberOfShares=portfolio.get(symbol)\n",
    "        if verbose==True:\n",
    "            print(\"************\")\n",
    "            if message!=None:\n",
    "                print(message)\n",
    "            print(\"Selling \"+str(numberOfShares)+\" \"+symbol+\" at \"+str(price)+\" totalling \"+str(numberOfShares*price))\n",
    "            print(\"Funds now: \"+str(funds))\n",
    "        portfolio.pop(symbol, None)\n",
    "        \n",
    "def removePics():\n",
    "    import os\n",
    "    dir_name = \"./bin/\"\n",
    "    test = os.listdir(dir_name)\n",
    "    for item in test:\n",
    "        if item.endswith(\".png\"):\n",
    "            os.remove(os.path.join(dir_name, item))\n",
    "\n",
    "def generatePDF(imageList, imagesPrPage=1):   \n",
    "    pdf=FPDF()\n",
    "    #pdf.add_page()\n",
    "    p=1\n",
    "    for count, image in enumerate(imageList):\n",
    "        if count%imagesPrPage == 0:\n",
    "            pdf.add_page()\n",
    "        pdf.image(image, x=None, y=None, w=160, h=80)\n",
    "    pdf.output('output.pdf',\"F\")\n",
    "\n",
    "def RSI(df, column=\"Close\", period=14):\n",
    "    # wilder's RSI \n",
    "    #pd.to_numeric(s, errors='coerce')\n",
    "    #d=pd.to_numeric(df[column])\n",
    "    d=pd.to_numeric(df[column])\n",
    "    delta = d.diff()\n",
    "    \n",
    "    up, down = delta.copy(), delta.copy()\n",
    "    up[up < 0] = 0\n",
    "    down[down > 0] = 0\n",
    "    rUp = up.ewm(com=period - 1,  adjust=False).mean()\n",
    "    rDown = down.ewm(com=period - 1, adjust=False).mean().abs()\n",
    "    rsi = 100 - 100 / (1 + rUp / rDown)    \n",
    "#    #return df.join(rsi.to_frame('RSI'))\n",
    "    print(type(list(rsi)))\n",
    "    return list(rsi)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def runSmaAnalysis(plot, verbose, symbols):\n",
    "    global funds\n",
    "    global portfolio\n",
    "    signals = {}\n",
    "    imageList = []\n",
    "    #symbols = ['SPNO.CPH','NOVO-B.CPH']\n",
    "    #29\n",
    "    #23\n",
    "    short = 20\n",
    "    long = 90\n",
    "    stopLoss = .04\n",
    "    #del result\n",
    "    for symbol in symbols:\n",
    "        fundsBefore=funds\n",
    "        data = downloadSymbolHistory(symbol,'2999-12-31','download')\n",
    "        #days = [days for days in getTradingDays(symbol) if days >= '2017-07-01' and days < '2018-08-01']\n",
    "        days = [days for days in getTradingDays(symbol) if days >= '2017-07-01' and days <= datetime.date.today().strftime(\"%Y-%m-%d\")]\n",
    "        \n",
    "        \n",
    "        daysDate = pd.Series([pd.to_datetime(date).date() for date in days])\n",
    "        #data = data[data.index.isin(days)]\n",
    "        print(\"*****************************\") \n",
    "        print(\"Simmulating \"+str(len(days))+\" days for \"+symbol)\n",
    "        #print(\"Funds now: \"+str(funds))\n",
    "    \n",
    "    \n",
    "        # creating short ans long sma´s\n",
    "        sma_short = data.Close.rolling(window=short).mean() \n",
    "        sma_long  = data.Close.rolling(window=long).mean() \n",
    "    \n",
    "        # Creating prev-values for sma´s\n",
    "        prev_sma_short = sma_short.shift(1)\n",
    "        #prev_sma_short.name = 'prev_sma_long'\n",
    "    \n",
    "        prev_sma_long = sma_long.shift(1)\n",
    "        #prev_sma_long.name = 'prev_sma_long'\n",
    "        #pd.to_numeric(s, errors='coerce')\n",
    "        \n",
    "        rsi = RSI(data)\n",
    "    \n",
    "        p=pd.to_numeric(data['Close'], errors='coerce')\n",
    "        prev_close = p.shift(1)\n",
    "    \n",
    "        #result = pd.DataFrame({'Close':data['Close'],\n",
    "        result = pd.DataFrame({'Close':pd.to_numeric(data['Close'], errors='coerce'),\n",
    "                           'prev_close':prev_close,\n",
    "                           #'Date':data['Date'],\n",
    "                           'sma_short':sma_short,\n",
    "                           'prev_sma_short':prev_sma_short,\n",
    "                           'sma_long':sma_long,\n",
    "                           'prev_sma_long':prev_sma_long,\n",
    "                           'rsi':rsi}).dropna(axis=0)\n",
    "        result = result[result.index.isin(days)]\n",
    "\n",
    "        for day in days:\n",
    "            v = result.loc[day,]\n",
    "            if (v.Close-v.prev_close)/v.prev_close < -stopLoss:\n",
    "                #print(\"StopLoss\")\n",
    "                sell(symbol, v.Close, \"StopLoss !\")\n",
    "                #signals[symbol]='StopLoss'\n",
    "            elif (v.sma_short > v.sma_long) & (v.prev_sma_short < v.prev_sma_long):\n",
    "                buy(symbol, v.Close)\n",
    "            \n",
    "            elif (v.sma_short < v.sma_long) & (v.prev_sma_short > v.prev_sma_long):\n",
    "                #print(str(day)+\": Sell-signal\")\n",
    "                sell(symbol, v.Close)\n",
    "        if portfolio.get(symbol) != None:\n",
    "            v = result.iloc[-1]\n",
    "            sell(symbol,v.Close, 'Force selling simulation')\n",
    "        print(\"************\")\n",
    "        print(\"Total result: \")\n",
    "        print(str(round((funds-fundsBefore)/fundsBefore*100))+\"%\")\n",
    "        sigForPlot = str(day)+' No signal - close: '+str(v.Close)\n",
    "        \n",
    "        # Generating signals for the last tradingday\n",
    "        if (v.Close-v.prev_close)/v.prev_close < -stopLoss:\n",
    "            print(\"StopLoss\")\n",
    "            print(str((v.Close-v.prev_close)/v.prev_close))\n",
    "            print(\"Close \"+str(v.Close))\n",
    "            print(\"Prev Close \"+str(v.prev_close))\n",
    "            signals[symbol]='StopLoss'\n",
    "            sigForPlot = 'StopLoss: ' +str((v.Close-v.prev_close)/v.prev_close*100)+'%'\n",
    "        elif (v.sma_short > v.sma_long) & (v.prev_sma_short < v.prev_sma_long):\n",
    "            print(\"SMA Buy signal\")\n",
    "            signals[symbol]='SMA Buy'\n",
    "            sigForPlot = str(day)+' SMA Buy - close: '+str(v.Close)\n",
    "        elif (v.sma_short < v.sma_long) & (v.prev_sma_short > v.prev_sma_long):\n",
    "            print(\"SMA Sell signal\")\n",
    "            signals[symbol]='SMA Sell'\n",
    "            sigForPlot = str(day)+' SMA Buy - close: '+str(v.Close)\n",
    "        else:\n",
    "            print(\"No signal\")\n",
    "\n",
    "            \n",
    "        if plot==True:\n",
    "            f=plt.figure(figsize=(10,5))\n",
    "            f.suptitle(symbol, fontsize=16)\n",
    "            ax = f.add_subplot(111)\n",
    "            ax.set_title(sigForPlot)\n",
    "            ax.plot(daysDate, result.sma_short, label=\"SMA short\", color=\"red\")\n",
    "            ax.plot(daysDate, result.sma_long,  label=\"SMA long\", color=\"blue\")\n",
    "            #ax.plot(daysDate, pd.to_numeric(result.Close, errors='coerce'), color=\"black\")\n",
    "            ax.plot(daysDate, result.Close, color=\"black\")\n",
    "            ax.set_ylabel('Closing price', color='black')\n",
    "            ax.legend(loc='lower center')\n",
    "            #ax.yaxis.set_ticks(np.arange(100, 400, 50))\n",
    "            \n",
    "            ax2 = ax.twinx()\n",
    "            ax2.plot(daysDate, result.rsi, 'r-', color='grey')\n",
    "            ax2.set_ylabel('Relative Strength Index (RSI)', color='grey')\n",
    "            \n",
    "            horizontal30 = np.array([30 for i in range(len(daysDate))])  \n",
    "            ax2.plot(daysDate, horizontal30, 'r-', color='grey')\n",
    "            horizontal70 = np.array([70 for i in range(len(daysDate))])  \n",
    "            ax2.plot(daysDate, horizontal70, 'r-', color='grey')\n",
    "            \n",
    "            plt.show()\n",
    "            #result['Date'] = result.index\n",
    "            #result.plot()\n",
    "        f.savefig('./bin/'+symbol+\".png\")\n",
    "        imageList.append('./bin/'+symbol+\".png\")\n",
    "        print(\"Done simmulating\")\n",
    "        print(\"*****************************\")\n",
    "    generatePDF(imageList,3)\n",
    "    return signals\n",
    "\n",
    "\n",
    "# Do the analysis\n",
    "removePics()\n",
    "symbolsUSA = ['MMM','AXP','AAPL','BA','CAT','CVX','CSCO','KO','DIS','XOM','GS','HD','IBM','INTC',\\\n",
    "                  'JNJ','JPM','MCD','MRK','MSFT','NKE','PFE','PG','TRV','UTX','UNH','VZ','V','WMT','WBA']\n",
    "symbolsDK = ['MAERSK-A.CPH','MAERSK-B.CPH','BAVA.CPH','CARL-B.CPH','CHR.CPH','COLO-B.CPH'\\\n",
    "               ,'DANSKE.CPH','DSV.CPH','FLS.CPH','GEN.CPH','GN.CPH','ISS.CPH','JYSK.CPH','LUN.CPH'\\\n",
    "               ,'NOVO-B.CPH','NZYM-B.CPH','PNDORA.CPH','RBREW.CPH','SIM.CPH','TRYG.CPH','VWS.CPH','WDH.CPH'\\\n",
    "               ,'ORSTED.CPH']\n",
    "#symbols=symbolsUSA+symbolsDK\n",
    "#symbols = ['CRM']\n",
    "\n",
    "#signals = runSmaAnalysis(plot, verbose, symbols)\n",
    "#if len(signals) == 0:\n",
    "#    mailBody = 'No signals today'\n",
    "#else:\n",
    "#    mailBody = str(signals)\n",
    "#sendMail('pedersbak@gmail.com','pedersbak@gmail.com', mailBody,'Signals for today',['output.pdf'])\n",
    "#send_mail('pedersbak@gmail.com','pedersbak@gmail.com', 'Signals for today', mailBody, ['output.pdf'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "daysRun = []\n",
    "while True:\n",
    "    import time\n",
    "    if datetime.time(9, 30, 0, 0) < datetime.datetime.time(datetime.datetime.now()) and datetime.date.today().strftime(\"%Y-%m-%d\") not in daysRun:\n",
    "        clear_output()\n",
    "        daysRun.append(datetime.date.today().strftime(\"%Y-%m-%d\"))\n",
    "        removePics()\n",
    "        symbolsUSA = ['MMM','AXP','AAPL','BA','CAT','CVX','CSCO','KO','DIS','XOM','GS','HD','IBM','INTC',\\\n",
    "                  'JNJ','JPM','MCD','MRK','MSFT','NKE','PFE','PG','TRV','UTX','UNH','VZ','V','WMT','WBA','GOOGL']\n",
    "        symbolsDK = ['MAERSK-A.CPH','MAERSK-B.CPH','BAVA.CPH','CARL-B.CPH','CHR.CPH','COLO-B.CPH'\\\n",
    "               ,'DANSKE.CPH','DSV.CPH','FLS.CPH','GEN.CPH','GN.CPH','ISS.CPH','JYSK.CPH','LUN.CPH'\\\n",
    "               ,'NOVO-B.CPH','NZYM-B.CPH','PNDORA.CPH','RBREW.CPH','SIM.CPH','TRYG.CPH','VWS.CPH','WDH.CPH'\\\n",
    "               ,'ORSTED.CPH']\n",
    "        symbols=symbolsUSA+symbolsDK\n",
    "        signals = runSmaAnalysis(plot, verbose, symbols)\n",
    "        if len(signals) == 0:\n",
    "            mailBody = 'No signals today'\n",
    "        else:\n",
    "            mailBody = str(signals)\n",
    "        sendMail('pedersbak@gmail.com','pedersbak@gmail.com', mailBody,'Signals for today',['output.pdf'])\n",
    "        time.sleep(600)\n",
    "        #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daysRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
